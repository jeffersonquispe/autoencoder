{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(0)\n",
    "tf.set_random_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-1eedde87f71e>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/jose/.local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/jose/.local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /home/jose/.local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/jose/.local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/jose/.local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "n_samples = mnist.train.num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xavier_init(fan_in, fan_out, constant=1): \n",
    "    low = -constant*np.sqrt(6.0/(fan_in + fan_out)) \n",
    "    high = constant*np.sqrt(6.0/(fan_in + fan_out))\n",
    "\n",
    "    return tf.random_uniform((fan_in, fan_out), \n",
    "                             minval=low, maxval=high, \n",
    "                             dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariationalAutoencoder(object):\n",
    "    def __init__(self, network_architecture, transfer_fct=tf.nn.softplus, \n",
    "                 learning_rate=0.001, batch_size=100):\n",
    "        self.network_architecture = network_architecture\n",
    "        self.transfer_fct = transfer_fct\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        # Input\n",
    "        self.x = tf.placeholder(tf.float32, [None, network_architecture[\"n_input\"]])\n",
    "\n",
    "        self._create_network()\n",
    "        self._create_loss_optimizer()\n",
    "        \n",
    "        init = tf.global_variables_initializer()\n",
    "\n",
    "        # Launch the session\n",
    "        self.sess = tf.InteractiveSession()\n",
    "        self.sess.run(init)\n",
    "    \n",
    "    def getMeanAndSigma(self, X_sample):\n",
    "        z_mean_, z_log_sigma_sq = self.sess.run((self.z_mean, self.z_log_sigma_sq), \n",
    "                                  feed_dict={self.x: X_sample})        \n",
    "        return z_mean_, z_log_sigma_sq\n",
    "    \n",
    "    def _create_network(self):\n",
    "        # Initialize weights and biases\n",
    "        network_weights = self._initialize_weights(**self.network_architecture)\n",
    "\n",
    "        # Use recognition network to determine mean and \n",
    "        # (log) variance of Gaussian distribution in latent\n",
    "        # space\n",
    "        self.z_mean, self.z_log_sigma_sq = \\\n",
    "            self._recognition_network(network_weights[\"weights_recog\"], \n",
    "                                      network_weights[\"biases_recog\"])\n",
    "        \n",
    "        #print(self.z_mean.shape, self.z_log_sigma_sq.shape)\n",
    "        # Draw one sample z from Gaussian distribution\n",
    "        n_z = self.network_architecture[\"n_z\"]\n",
    "        eps = tf.random_normal((self.batch_size, n_z), 0, 1, \n",
    "                               dtype=tf.float32)\n",
    "        # z = mu + sigma*epsilon\n",
    "        self.z = tf.add(self.z_mean, tf.sqrt(tf.exp(self.z_log_sigma_sq)) * eps)\n",
    "\n",
    "        # Use generator to determine mean of\n",
    "        # Bernoulli distribution of reconstructed input\n",
    "        self.x_reconstr_mean = \\\n",
    "            self._generator_network(network_weights[\"weights_gener\"],\n",
    "                                    network_weights[\"biases_gener\"])\n",
    "            \n",
    "    def _initialize_weights(self, n_hidden_recog_1, n_hidden_recog_2, n_hidden_recog_3,\n",
    "                            n_hidden_gener_1,  n_hidden_gener_2, n_hidden_gener_3,\n",
    "                            n_input, n_z):\n",
    "        all_weights = dict()\n",
    "        all_weights['weights_recog'] = {\n",
    "            'h1': tf.Variable(xavier_init(n_input, n_hidden_recog_1)),\n",
    "            'h2': tf.Variable(xavier_init(n_hidden_recog_1, n_hidden_recog_2)),\n",
    "            'h3': tf.Variable(xavier_init(n_hidden_recog_2, n_hidden_recog_3)),\n",
    "            'out_mean': tf.Variable(xavier_init(n_hidden_recog_3, n_z)),\n",
    "            'out_log_sigma': tf.Variable(xavier_init(n_hidden_recog_3, n_z))}\n",
    "        all_weights['biases_recog'] = {\n",
    "            'b1': tf.Variable(tf.zeros([n_hidden_recog_1], dtype=tf.float32)),\n",
    "            'b2': tf.Variable(tf.zeros([n_hidden_recog_2], dtype=tf.float32)),\n",
    "            'b3': tf.Variable(tf.zeros([n_hidden_recog_3], dtype=tf.float32)),\n",
    "            'out_mean': tf.Variable(tf.zeros([n_z], dtype=tf.float32)),\n",
    "            'out_log_sigma': tf.Variable(tf.zeros([n_z], dtype=tf.float32))}\n",
    "        all_weights['weights_gener'] = {\n",
    "            'h1': tf.Variable(xavier_init(n_z, n_hidden_gener_1)),\n",
    "            'h2': tf.Variable(xavier_init(n_hidden_gener_1, n_hidden_gener_2)),\n",
    "            'h3': tf.Variable(xavier_init(n_hidden_gener_2, n_hidden_gener_3)),\n",
    "            'out_mean': tf.Variable(xavier_init(n_hidden_gener_3, n_input)),\n",
    "            'out_log_sigma': tf.Variable(xavier_init(n_hidden_gener_3, n_input))}\n",
    "        all_weights['biases_gener'] = {\n",
    "            'b1': tf.Variable(tf.zeros([n_hidden_gener_1], dtype=tf.float32)),\n",
    "            'b2': tf.Variable(tf.zeros([n_hidden_gener_2], dtype=tf.float32)),\n",
    "            'b3': tf.Variable(tf.zeros([n_hidden_gener_3], dtype=tf.float32)),\n",
    "            'out_mean': tf.Variable(tf.zeros([n_input], dtype=tf.float32)),\n",
    "            'out_log_sigma': tf.Variable(tf.zeros([n_input], dtype=tf.float32))}\n",
    "        return all_weights\n",
    "            \n",
    "    def _recognition_network(self, weights, biases):\n",
    "        # Generate probabilistic encoder \n",
    "        \n",
    "        layer_1 = self.transfer_fct(tf.add(tf.matmul(self.x, weights['h1']), \n",
    "                                           biases['b1'])) \n",
    "        layer_2 = self.transfer_fct(tf.add(tf.matmul(layer_1, weights['h2']), \n",
    "                                           biases['b2'])) \n",
    "        layer_3 = self.transfer_fct(tf.add(tf.matmul(layer_2, weights['h3']), \n",
    "                                           biases['b3'])) \n",
    "        \n",
    "        z_mean         = tf.add(tf.matmul(layer_3, weights['out_mean']),\n",
    "                                biases['out_mean'])\n",
    "        \n",
    "        z_log_sigma_sq = tf.add(tf.matmul(layer_3, weights['out_log_sigma']), \n",
    "                                biases['out_log_sigma'])\n",
    "        \n",
    "        return (z_mean, z_log_sigma_sq)\n",
    "\n",
    "    def _generator_network(self, weights, biases):\n",
    "        # Generate probabilistic decoder\n",
    "        \n",
    "        layer_1 = self.transfer_fct(tf.add(tf.matmul(self.z, weights['h1']), \n",
    "                                           biases['b1'])) \n",
    "        layer_2 = self.transfer_fct(tf.add(tf.matmul(layer_1, weights['h2']), \n",
    "                                           biases['b2'])) \n",
    "        layer_3 = self.transfer_fct(tf.add(tf.matmul(layer_2, weights['h3']), \n",
    "                                           biases['b3'])) \n",
    "        \n",
    "        x_reconstr_mean = tf.nn.sigmoid(tf.add(tf.matmul(layer_3, weights['out_mean']), \n",
    "                                        biases['out_mean']))\n",
    "        return x_reconstr_mean\n",
    "            \n",
    "    def _create_loss_optimizer(self):\n",
    "        # Two loss:\n",
    "        #\n",
    "        # 1.) The reconstruction loss (the negative log probability\n",
    "        #     of the input under the reconstructed Bernoulli distribution \n",
    "        #     induced by the decoder in the data space).\n",
    "        #     This can be interpreted as the number of \"nats\" required\n",
    "        #     for reconstructing the input when the activation in latent\n",
    "        #     is given.\n",
    "        \n",
    "        \n",
    "        # Adding 1e-10 to avoid evaluation of log(0.0)\n",
    "        reconstr_loss = \\\n",
    "            -tf.reduce_sum(self.x * tf.log(1e-10 + self.x_reconstr_mean)\n",
    "                           + (1-self.x) * tf.log(1e-10 + 1 - self.x_reconstr_mean),\n",
    "                           1)\n",
    "        \n",
    "        # 2.) The latent loss, which is defined as the Kullback Leibler divergence \n",
    "        ##    between the distribution in latent space induced by the encoder on \n",
    "        #     the data and some prior. This acts as a kind of regularizer.\n",
    "        #     This can be interpreted as the number of \"nats\" required\n",
    "        #     for transmitting the the latent space distribution given\n",
    "        #     the prior.\n",
    "        \n",
    "        latent_loss = -0.5 * tf.reduce_sum(1 + self.z_log_sigma_sq \n",
    "                                           - tf.square(self.z_mean) \n",
    "                                           - tf.exp(self.z_log_sigma_sq), 1)\n",
    "        \n",
    "        # average over batch\n",
    "        self.cost = tf.reduce_mean(reconstr_loss + latent_loss)   \n",
    "        \n",
    "        # Use ADAM optimizer\n",
    "        self.optimizer = \\\n",
    "            tf.train.AdamOptimizer(learning_rate=self.learning_rate).minimize(self.cost)\n",
    "        \n",
    "    def partial_fit(self, X):\n",
    "        opt, cost = self.sess.run((self.optimizer, self.cost), \n",
    "                                  feed_dict={self.x: X})\n",
    "        return cost\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return self.sess.run(self.z_mean, feed_dict={self.x: X})\n",
    "    \n",
    "    def generate(self, z_mu=None):\n",
    "        \"\"\" Generate data by sampling from latent space.\n",
    "        \n",
    "        If z_mu is not None, data for this point in latent space is\n",
    "        generated. Otherwise, z_mu is drawn from prior in latent \n",
    "        space.        \n",
    "        \"\"\"\n",
    "        if z_mu is None:\n",
    "            z_mu = np.random.normal(size=self.network_architecture[\"n_z\"])\n",
    "        \n",
    "        return self.sess.run(self.x_reconstr_mean, \n",
    "                             feed_dict={self.z: z_mu})\n",
    "    \n",
    "    def reconstruct(self, X):\n",
    "        \"\"\" Use VAE to reconstruct given data. \"\"\"\n",
    "        return self.sess.run(self.x_reconstr_mean, \n",
    "                             feed_dict={self.x: X})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(network_architecture, learning_rate=0.001,\n",
    "          batch_size=100, training_epochs=10, display_step=5):\n",
    "    vae = VariationalAutoencoder(network_architecture, \n",
    "                                 learning_rate=learning_rate, \n",
    "                                 batch_size=batch_size)\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.\n",
    "        total_batch = int(n_samples / batch_size)\n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "            batch_xs, _ = mnist.train.next_batch(batch_size)\n",
    "\n",
    "            # Fit training using batch data\n",
    "            cost = vae.partial_fit(batch_xs)\n",
    "            # Compute average loss\n",
    "            avg_cost += cost / n_samples * batch_size\n",
    "\n",
    "        # Display logs per epoch step\n",
    "        if epoch % display_step == 0:\n",
    "            print(\"Epoch:\", '%04d' % (epoch+1), \n",
    "                  \"cost=\", \"{:.9f}\".format(avg_cost))\n",
    "    return vae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstruction quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost= 192.559436951\n",
      "Epoch: 0006 cost= 119.691278270\n",
      "Epoch: 0011 cost= 111.840565116\n",
      "Epoch: 0016 cost= 108.028469946\n",
      "Epoch: 0021 cost= 105.842706160\n",
      "Epoch: 0026 cost= 104.242836651\n",
      "Epoch: 0031 cost= 103.134686043\n",
      "Epoch: 0036 cost= 102.440753992\n",
      "Epoch: 0041 cost= 101.681984184\n",
      "Epoch: 0046 cost= 101.089719571\n",
      "Epoch: 0051 cost= 100.728096757\n",
      "Epoch: 0056 cost= 100.187025604\n",
      "Epoch: 0061 cost= 100.016102392\n",
      "Epoch: 0066 cost= 99.674692216\n",
      "Epoch: 0071 cost= 99.321160639\n"
     ]
    }
   ],
   "source": [
    "network_architecture = \\\n",
    "    dict(n_hidden_recog_1=400, # 1st layer encoder neurons\n",
    "         n_hidden_recog_2=200, # 2nd layer encoder neurons\n",
    "         n_hidden_recog_3=100, # 3th layer encoder neurons\n",
    "         n_hidden_gener_1=100, # 1st layer decoder neurons\n",
    "         n_hidden_gener_2=200, # 2nd layer decoder neurons\n",
    "         n_hidden_gener_3=400, # 3th layer decoder neurons\n",
    "         n_input=784,          # MNIST data input (img shape: 28*28)\n",
    "         n_z=20)               # dimensionality of latent space\n",
    "\n",
    "vae = train(network_architecture, training_epochs=75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getImagefromDataset(num):\n",
    "    xs, ys = mnist.train.next_batch(1000)\n",
    "    \n",
    "    xs_l = []\n",
    "    \n",
    "    for i in range(1000):\n",
    "        if np.argmax(ys[i]) == num:\n",
    "            xs_l.append(xs[i])\n",
    "    \n",
    "    if len(xs_l) > 0:\n",
    "        return xs_l[0]\n",
    "    else: \n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVAEImage(num):\n",
    "    imgX    = getImagefor(num)\n",
    "    mu, sig = vae.getMeanAndSigma([imgX])   \n",
    "    eps     = np.random.normal( 0, 1,(1, 20))\n",
    "    z_      = mu + np.sqrt(np.exp(sig)) * eps\n",
    "    z_mu    = np.array([z_[0]]*vae.batch_size)\n",
    "    z_.shape, z_mu.shape\n",
    "    x_mean  = vae.generate(z_mu)\n",
    "    img     = x_mean[0].reshape(28,28)\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f3645683860>"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAED9JREFUeJzt3WuMVWWWxvFnCS0iFxHRCiCRxuBd0QHJJKOmTUtraxs1JEZJDBNN0x80mTaTOMb5MCaTiWYy3ZP+oglGI05auyfxhtoZ2zETwUuMKIgitDhYBJCLV5SLMhRrPtSmU6111lueS+1TrP8vIXVqr/Oeejnw1D7nrL33a+4uAPkcVfcEANSD8ANJEX4gKcIPJEX4gaQIP5AU4QeSIvxAUoQfSGr0cP4wM+NwQqDD3N2Gcr+W9vxmdoWZ/cnMPjCzO1t5LADDy5o9tt/MRkl6X9ICSVslvSHpRnd/LxjDnh/osOHY88+X9IG7b3L3A5J+J+maFh4PwDBqJfzTJW0Z8P3WattfMLMlZrbKzFa18LMAtFnHP/Bz96WSlkq87Ae6SSt7/m2SZgz4/uRqG4ARoJXwvyFptpn90MyOlnSDpOXtmRaATmv6Zb+7HzSz2yQ9L2mUpIfcfV3bZgago5pu9TX1w3jPD3TcsBzkA2DkIvxAUoQfSIrwA0kRfiApwg8kRfiBpAg/kBThB5Ii/EBShB9IivADSRF+ICnCDyRF+IGkCD+QFOEHkiL8QFKEH0iK8ANJEX4gqWFdohvNMYsvxnrUUc3/Dj906FBYH86rO39fnXxe+vr6mh47UrDnB5Ii/EBShB9IivADSRF+ICnCDyRF+IGkWurzm1mvpK8k9Uk66O7z2jGpI02pHz16dPzP0NPTE9bPOOOMhrXx48eHY7/55puwXprb5MmTw/pZZ53VsHbaaaeFY6dMmRLWS3386O/W29sbjl25cmVY37hxY1jfvHlzWP/oo48a1obrGIN2HORzqbt/0obHATCMeNkPJNVq+F3SH83sTTNb0o4JARgerb7sv8jdt5nZSZJeMLMN7r5i4B2qXwr8YgC6TEt7fnffVn3dJelJSfMHuc9Sd5/Hh4FAd2k6/GY2zswmHL4t6SeS3m3XxAB0Visv+3skPVm1sUZLetTd/6stswLQcU2H3903SZrTxrkcsUr96OOOOy6sz5kTP81XXXVVw1rUZ5ekk08+OayXeu2l4whGjRoV1iOlfvf+/fvD+p49exrWSv8mpT7+6tWrw/pIQKsPSIrwA0kRfiApwg8kRfiBpAg/kBSX7m6DVk/ZnTlzZlhftGhRWL/kkksa1iZOnBiOHTt2bFhvpVUnSQcOHGhY27t3bzj2k0/ik0U3bdoU1jds2NCw9vbbb4djX3311bC+Y8eOsF5qQ3bDpcHZ8wNJEX4gKcIPJEX4gaQIP5AU4QeSIvxAUvT5h0Gpz1867fbCCy8M6xMmTGhY27dvXzi21Csv9cPXrFkT1tetW9ewVrq89e7du8N6qZceKS09Xnrs0tLmpXo3YM8PJEX4gaQIP5AU4QeSIvxAUoQfSIrwA0nR52+D0vn8xx57bFhfsGBBWC+dk//ll182rD311FPh2Pvuuy+sb9myJayXlviO+t2d7oVH/y6lPn8G7PmBpAg/kBThB5Ii/EBShB9IivADSRF+IKlin9/MHpL0M0m73P2cattkSb+XNFNSr6Tr3f3zzk2zu5WWez711FPD+vz588N6qR/+/vvvN6wtX748HFu6Nn6pH166rn+d/XR6+bGh7PkflnTFt7bdKelFd58t6cXqewAjSDH87r5C0mff2nyNpGXV7WWSrm3zvAB0WLPv+XvcfXt1e4eknjbNB8AwafnYfnd3M2v45srMlkha0urPAdBeze75d5rZVEmqvu5qdEd3X+ru89x9XpM/C0AHNBv+5ZIWV7cXS3q6PdMBMFyK4TezxyS9Jul0M9tqZrdIulfSAjPbKOmy6nsAI0jxPb+739ig9OM2z6WrReeGl9a4v/rqq8P6pEmTmprTYdFxAJdeemk4du7cuU0/tiQdc8wxYT261sDq1avDsevXrw/rpev6Hzx4sGFtJFxXv9M4wg9IivADSRF+ICnCDyRF+IGkCD+QFJfuHqJome2envjUhjPPPLPpx5bK7bSoXXfeeeeFY0uXHS/Vx4wZE9aj051L7bbe3t6wvmLFirB+//33N6xFp0FLcZvwSMGeH0iK8ANJEX4gKcIPJEX4gaQIP5AU4QeSos9fKfWzo371KaecEo4t9elLSscBREuAl/rVfX19Yb20BPf+/fvDejT30jECs2bNCuvTpk0L61OmTGlYu/XWW8Oxn3327WvWHnnY8wNJEX4gKcIPJEX4gaQIP5AU4QeSIvxAUvT5K6XlnKPjAEpLdG/YsCGsH3/88WF98uTJYT2a2/bt2xvWJOmFF14I66+88kpYL/X5o+d14cKF4djSJc+nTp0a1ufMmdOwdu6554ZjS9cKOBKW/2bPDyRF+IGkCD+QFOEHkiL8QFKEH0iK8ANJFfv8ZvaQpJ9J2uXu51Tb7pb0c0kfV3e7y93/0KlJdoPovPcPP/wwHPv888+H9dJS1KNGjQrrUa/99ddfD8du3rw5rJfO52/l+IjS37t0jMLtt98e1qOl02fPnh2Offnll8N66ToII8FQ9vwPS7pikO3/7u7nV3+O6OADR6Ji+N19haQj/7ImQDKtvOe/zczWmtlDZhYfnwqg6zQb/vslnSrpfEnbJf2q0R3NbImZrTKzVU3+LAAd0FT43X2nu/e5+yFJD0iaH9x3qbvPc/d5zU4SQPs1FX4zG3g61XWS3m3PdAAMl6G0+h6T9CNJU8xsq6R/kvQjMztfkkvqlfSLDs4RQAcUw+/uNw6y+cEOzKWrRefs79y5Mxy7e/fusL5mzZqwfuDAgbAerXO/d+/ecGyn16GPjgMoze21114L6zfffHNYHz9+fMPajBkzwrGlazRk6fMDOAIRfiApwg8kRfiBpAg/kBThB5Li0t2V0hLdUTutdFrr119/HdZLrbxW2kojuSU1ceLEsD5p0qSwHp0KvW/fvnDskXBp7hL2/EBShB9IivADSRF+ICnCDyRF+IGkCD+QFH3+IYqOAyj1o0s9488//zysR8cYlB6/m/vVEyZMCOuLFi0K66U+/xdffNGwtnbt2nDsSD4+YqjY8wNJEX4gKcIPJEX4gaQIP5AU4QeSIvxAUvT5K6Xz+aNe/qxZs8KxpSW2161bF9ZLxwG0otPHAYwZM6Zh7aabbgrHXn755WH96KOPDusff/xxw9qqVfHqcd18fES7sOcHkiL8QFKEH0iK8ANJEX4gKcIPJEX4gaSKfX4zmyHpEUk9klzSUnf/jZlNlvR7STMl9Uq63t0715DusFKf/4QTTmhYu/jii8Ox06ZNC+snnnhiWF+5cmVYj44DKC3BXfp7l5aqHjt2bFi/7rrrGtbuuOOOcOyUKVPCemmJ7wceeKBh7dNPPw3HZjCUPf9BSX/v7mdJ+mtJt5rZWZLulPSiu8+W9GL1PYARohh+d9/u7m9Vt7+StF7SdEnXSFpW3W2ZpGs7NUkA7fe93vOb2UxJF0h6XVKPu2+vSjvU/7YAwAgx5GP7zWy8pMcl/dLdvxz4XtHd3cwGPRjazJZIWtLqRAG015D2/Gb2A/UH/7fu/kS1eaeZTa3qUyXtGmysuy9193nuPq8dEwbQHsXwW/8u/kFJ69391wNKyyUtrm4vlvR0+6cHoFOG8rL/byTdJOkdM1tTbbtL0r2S/tPMbpG0WdL1nZlie5ROqy21tMaNG9ewNnfu3HDs6aefHtbnz58f1i+44IKw/swzzzSsRZevlsqXv54+fXpYX7hwYViP2qA9PfHHRKWlzR999NGwvmzZsoa10uXQMyiG391fltSoGfzj9k4HwHDhCD8gKcIPJEX4gaQIP5AU4QeSIvxAUmku3d1qn3/fvn0Na1u2bAnHzpkzJ6zPnDkzrJeOE7jhhhsa1vbs2ROOLS2TXTrdePTo+L9QdErxzp07w7GlPv4999wT1vfv3x/Ws2PPDyRF+IGkCD+QFOEHkiL8QFKEH0iK8ANJpenzly5hXepXR5d6fu6555qa02GXXXZZWC9d+vukk05qWCudj186vqGvry+s7969O6xHy48//PDD4dhnn322pZ+dYZntVrDnB5Ii/EBShB9IivADSRF+ICnCDyRF+IGkbDh7oY2W9BoJousBTJw4MRw7e/bssH722WeH9XPOOSesR33+aGlxqdznL12r4KWXXmq6vmvXoIs8/dmBAwfCOn38wbl7vO56hT0/kBThB5Ii/EBShB9IivADSRF+ICnCDyRV7POb2QxJj0jqkeSSlrr7b8zsbkk/l/Rxdde73P0PhceiMQt02FD7/EMJ/1RJU939LTObIOlNSddKul7SHnf/t6FOivADnTfU8Bev5OPu2yVtr25/ZWbrJcWXhwHQ9b7Xe34zmynpAkmvV5tuM7O1ZvaQmR3fYMwSM1tlZqtamimAthrysf1mNl7SS5L+xd2fMLMeSZ+o/3OAf1b/W4ObC4/By36gw9r2nl+SzOwHkp6V9Ly7/3qQ+kxJz7p7eAYK4Qc6r20n9piZSXpQ0vqBwa8+CDzsOknvft9JAqjPUD7tv0jSSknvSDpUbb5L0o2Szlf/y/5eSb+oPhyMHos9P9BhbX3Z3y6EH+g8zucHECL8QFKEH0iK8ANJEX4gKcIPJEX4gaQIP5AU4QeSIvxAUoQfSIrwA0kRfiApwg8kVbyAZ5t9ImnzgO+nVNu6UbfOrVvnJTG3ZrVzbqcM9Y7Dej7/d3642Sp3n1fbBALdOrdunZfE3JpV19x42Q8kRfiBpOoO/9Kaf36kW+fWrfOSmFuzaplbre/5AdSn7j0/gJrUEn4zu8LM/mRmH5jZnXXMoREz6zWzd8xsTd1LjFXLoO0ys3cHbJtsZi+Y2cbq66DLpNU0t7vNbFv13K0xsytrmtsMM/sfM3vPzNaZ2d9V22t97oJ51fK8DfvLfjMbJel9SQskbZX0hqQb3f29YZ1IA2bWK2meu9feEzazSyTtkfTI4dWQzOxfJX3m7vdWvziPd/d/6JK53a3vuXJzh+bWaGXpv1WNz107V7xuhzr2/PMlfeDum9z9gKTfSbqmhnl0PXdfIemzb22+RtKy6vYy9f/nGXYN5tYV3H27u79V3f5K0uGVpWt97oJ51aKO8E+XtGXA91vVXUt+u6Q/mtmbZrak7skMomfAykg7JPXUOZlBFFduHk7fWlm6a567Zla8bjc+8Puui9z9ryT9VNKt1cvbruT979m6qV1zv6RT1b+M23ZJv6pzMtXK0o9L+qW7fzmwVudzN8i8anne6gj/NkkzBnx/crWtK7j7turrLklPqv9tSjfZeXiR1Orrrprn82fuvtPd+9z9kKQHVONzV60s/bik37r7E9Xm2p+7weZV1/NWR/jfkDTbzH5oZkdLukHS8hrm8R1mNq76IEZmNk7ST9R9qw8vl7S4ur1Y0tM1zuUvdMvKzY1WllbNz13XrXjt7sP+R9KV6v/E/38l/WMdc2gwr1mS3q7+rKt7bpIeU//LwP9T/2cjt0g6QdKLkjZK+m9Jk7tobv+h/tWc16o/aFNrmttF6n9Jv1bSmurPlXU/d8G8anneOMIPSIoP/ICkCD+QFOEHkiL8QFKEH0iK8ANJEX4gKcIPJPX/oFJhU3jn5Y8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = getVAEImage(5)\n",
    "\n",
    "plt.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = np.load('samples.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getListOfNumbers(sNUM):\n",
    "    res = []\n",
    "    for i in range(len(sNUM)):\n",
    "        img = getVAEImage(int(sNUM[i]))\n",
    "        res.append(img)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a number : 56894\n"
     ]
    }
   ],
   "source": [
    "NUM = input(\"Enter a number : \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_imgs = getListOfNumbers(NUM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f364579c7f0>"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(input_imgs[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
